{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34ffbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 14:42:58.152099: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import LogNorm\n",
    "import urllib.request\n",
    "import os \n",
    "\n",
    "#############################\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896d000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroFile = 'data/train/jetImage_0_100p_0_10000.h5'\n",
    "firstFile = 'data/train/jetImage_1_100p_0_10000.h5'\n",
    "secondFile = 'data/train/jetImage_2_100p_0_10000.h5'\n",
    "thirdFile = 'data/train/jetImage_3_100p_0_10000.h5'\n",
    "fourthFile = 'data/train/jetImage_4_100p_0_10000.h5'\n",
    "\n",
    "    \n",
    "if not os.path.isfile(zeroFile):\n",
    "    if not os.path.isdir('data/train'):\n",
    "        os.makedirs('data/train')\n",
    "   \n",
    "    urllib.request.urlretrieve('http://www.hep.ucl.ac.uk/undergrad/0056/other/projects/jetimage/'+zeroFile, zeroFile)\n",
    "\n",
    "\n",
    "if not os.path.isfile(firstFile):\n",
    "    if not os.path.isdir('data/train'):\n",
    "        os.makedirs('data/train')\n",
    "   \n",
    "    urllib.request.urlretrieve('http://www.hep.ucl.ac.uk/undergrad/0056/other/projects/jetimage/'+firstFile, firstFile)\n",
    "\n",
    "    \n",
    "if not os.path.isfile(secondFile):\n",
    "    if not os.path.isdir('data/train'):\n",
    "        os.makedirs('data/train')\n",
    "   \n",
    "    urllib.request.urlretrieve('http://www.hep.ucl.ac.uk/undergrad/0056/other/projects/jetimage/'+secondFile, secondFile)\n",
    "\n",
    "\n",
    "if not os.path.isfile(thirdFile):\n",
    "    if not os.path.isdir('data/train'):\n",
    "        os.makedirs('data/train')\n",
    "   \n",
    "    urllib.request.urlretrieve('http://www.hep.ucl.ac.uk/undergrad/0056/other/projects/jetimage/'+thirdFile, thirdFile)\n",
    "\n",
    "\n",
    "if not os.path.isfile(fourthFile):\n",
    "    if not os.path.isdir('data/train'):\n",
    "        os.makedirs('data/train')\n",
    "   \n",
    "    urllib.request.urlretrieve('http://www.hep.ucl.ac.uk/undergrad/0056/other/projects/jetimage/'+fourthFile, fourthFile)\n",
    "\n",
    "\n",
    "df=h5py.File(zeroFile,'r')\n",
    "df1=h5py.File(firstFile,'r')\n",
    "df2=h5py.File(secondFile,'r')\n",
    "df3=h5py.File(thirdFile,'r')\n",
    "df4=h5py.File(fourthFile,'r')\n",
    "\n",
    "#############################################\n",
    "\n",
    "data1_zero = np.array(df.get('jetConstituentList'))\n",
    "data1_first = np.array(df1.get('jetConstituentList'))\n",
    "data1_second = np.array(df2.get('jetConstituentList'))\n",
    "data1_third = np.array(df3.get('jetConstituentList'))\n",
    "data1_fourth = np.array(df4.get('jetConstituentList'))\n",
    "\n",
    "data3_zero = np.array(df.get('jetImage'))  \n",
    "data3_first = np.array(df1.get('jetImage')) \n",
    "data3_second = np.array(df2.get('jetImage')) \n",
    "data3_third = np.array(df3.get('jetImage')) \n",
    "data3_fourth = np.array(df4.get('jetImage')) \n",
    "\n",
    "data4_zero = np.array(df.get('jetImageECAL'))  \n",
    "data4_first = np.array(df1.get('jetImageECAL'))\n",
    "data4_second = np.array(df2.get('jetImageECAL'))\n",
    "data4_third = np.array(df3.get('jetImageECAL'))\n",
    "data4_fourth = np.array(df4.get('jetImageECAL'))\n",
    "\n",
    "data5_zero = np.array(df.get('jetImageHCAL'))  \n",
    "data5_first = np.array(df1.get('jetImageHCAL'))  \n",
    "data5_second = np.array(df2.get('jetImageHCAL'))  \n",
    "data5_third = np.array(df3.get('jetImageHCAL'))  \n",
    "data5_fourth = np.array(df4.get('jetImageHCAL'))  \n",
    "\n",
    "data6_zero = np.array(df.get('jets')) \n",
    "data6_first = np.array(df1.get('jets')) \n",
    "data6_second = np.array(df2.get('jets')) \n",
    "data6_third = np.array(df3.get('jets')) \n",
    "data6_fourth = np.array(df4.get('jets')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f39b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['jetConstituentList', 'jetFeatureNames', 'jetImage', 'jetImageECAL', 'jetImageHCAL', 'jets', 'particleFeatureNames']>\n"
     ]
    }
   ],
   "source": [
    "# Concatenate datasets along the first axis\n",
    "jetConstituentList = np.concatenate((data1_zero, data1_first, data1_second, data1_third, data1_fourth), axis=0)\n",
    "\n",
    "jetImage = np.concatenate((data3_zero, data3_first, data3_second, data3_third, data3_fourth), axis=0)\n",
    "jetImageECAL = np.concatenate((data4_zero, data4_first, data4_second, data4_third, data4_fourth), axis=0)\n",
    "jetImageHCAL = np.concatenate((data5_zero, data5_first, data5_second, data5_third, data5_fourth), axis=0)\n",
    "\n",
    "jets = np.concatenate((data6_zero, data6_first, data6_second, data6_third, data6_fourth), axis=0)\n",
    "\n",
    "\n",
    "# Print the shape of the combined data\n",
    "print(df.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ea607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------ Particle Encoding -------------------------\n",
      "\n",
      " Gluon: [1. 0. 0. ... 0. 0. 0.]\n",
      " Quark: [0. 0. 0. ... 0. 2. 0.]\n",
      " W boson: [0. 3. 0. ... 0. 0. 0.]\n",
      " Z boson: [0. 0. 0. ... 0. 0. 0.]\n",
      " Top: [0. 0. 5. ... 5. 0. 5.]\n",
      "\n",
      "particle_label_array: [1. 3. 5. ... 5. 2. 5.] shape:(50000,)\n",
      "check max: 5.0\n",
      "check min: 1.0\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print('------------------------ Particle Encoding -------------------------')\n",
    "print(\"\")\n",
    "\n",
    "# Assigning number to particles \n",
    "G = 1*np.array(jets[:,-6])\n",
    "Q = 2*np.array(jets[:,-5])\n",
    "W = 3*np.array(jets[:,-4])\n",
    "Z = 4*np.array(jets[:,-3])\n",
    "T = 5*np.array(jets[:,-2])\n",
    "\n",
    "print(f\" Gluon: {G}\")\n",
    "print(f\" Quark: {Q}\")\n",
    "print(f\" W boson: {W}\")\n",
    "print(f\" Z boson: {Z}\")\n",
    "print(f\" Top: {T}\")\n",
    "print(\"\")\n",
    "\n",
    "particle_label_array = G+Q+W+Z+T\n",
    "\n",
    "print(f\"particle_label_array: {particle_label_array} shape:{particle_label_array.shape}\")\n",
    "print(f\"check max:\",max(particle_label_array))\n",
    "print(f\"check min:\",min(particle_label_array))\n",
    "\n",
    "print(\"\")\n",
    "print('-----------------------------------------------------------------')\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce0c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(jetImage, particle_label_array, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4566d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST NEED TO ADD THIS \n",
    "\n",
    "###############################################################################################\n",
    "##                                                                                           ##\n",
    "##                                                                                           ##\n",
    "###############################################################################################  \n",
    "\n",
    "train_images_rot = np.copy(train_images) # Duplicating the array\n",
    "\n",
    "rotated_indices = np.random.choice(train_images_rot.shape[0], size=int(0.2 * train_images_rot.shape[0]), replace=False)\n",
    "\n",
    "# Rotate randomly by 90, 180, or 270 degrees\n",
    "for idx in rotated_indices:\n",
    "    k = np.random.choice([1, 2, 3])  # Randomly choose 1, 2, or 3 for 90-degree rotations\n",
    "    rotated_image = np.rot90(train_images_rot[idx], k=k)\n",
    "    train_images_rot[idx] = rotated_image\n",
    "\n",
    "###############################################################################################\n",
    "##                                                                                           ##\n",
    "##                                                                                           ##\n",
    "############################################################################################### \n",
    "\n",
    "train_images_ref = np.copy(train_images)\n",
    "\n",
    "flipped_indices = np.random.choice(train_images_ref.shape[0], size=int(0.2 * train_images_ref.shape[0]), replace=False)\n",
    "\n",
    "# Flip horizontally or vertically randomly\n",
    "for idx in flipped_indices:\n",
    "    if np.random.rand() > 0.3:\n",
    "        train_images_rot[idx] = np.flip(train_images_ref[idx], axis=0)  # Vertical flip\n",
    "    else:\n",
    "        train_images_rot[idx] = np.flip(train_images_ref[idx], axis=1)  # Horizontal flip\n",
    "\n",
    "###############################################################################################\n",
    "##                                                                                           ##\n",
    "##                                                                                           ##\n",
    "############################################################################################### \n",
    "\n",
    "train_images_rot_ref = np.copy(train_images)\n",
    "\n",
    "transformed_indices = np.random.choice(train_images.shape[0], size=int(0.2 * train_images.shape[0]), replace=False)\n",
    "\n",
    "# Rotation and reflection\n",
    "for idx in transformed_indices:\n",
    "    # Randomly choose 1, 2, or 3 for 90-degree rotations\n",
    "    k = np.random.choice([1, 2, 3])\n",
    "    \n",
    "    # Rotate the image\n",
    "    rotated_image = np.rot90(train_images_rot_ref[idx], k=k)\n",
    "    \n",
    "    # Randomly choose whether to flip horizontally with 30% probability\n",
    "    if np.random.rand() < 0.3:\n",
    "        rotated_image = np.fliplr(rotated_image)\n",
    "    \n",
    "    train_images_rot_ref[idx] = rotated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83abc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise function \n",
    "\n",
    "def noise(img_arr,y_noise):\n",
    "    \"\"\"\n",
    "     \n",
    "    Add random noise to an array of images.\n",
    "\n",
    "    Inputs:\n",
    "    - img_arr: Input array representing a batch of images.\n",
    "    - y_noise: Maximum magnitude of the uniform distribution used to generate noise.\n",
    "\n",
    "    Returns:\n",
    "    - noise_img: Array of images with added random noise.\n",
    "    \n",
    "    \"\"\"\n",
    "    # noise array size of images array\n",
    "    noise = np.random.uniform(low=0,high=y_noise,size=(100,100))#uniform distribution for the noise\n",
    "    \n",
    "    noise_img=img_arr + noise/255.0   #adding normalised noise to image\n",
    "        \n",
    "    return noise_img\n",
    "\n",
    "y_noise = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ec74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(images):\n",
    "    # Reshape the images to 2D arrays if they're currently 3D\n",
    "    if images.ndim == 3:\n",
    "        num_images, height, width = images.shape\n",
    "        images = images.reshape(num_images, -1)\n",
    "    \n",
    "    # Normalize each image separately\n",
    "    normalized_images = []\n",
    "    for image in images:\n",
    "        min_val = np.min(image)\n",
    "        max_val = np.max(image)\n",
    "        normalized_image = (image - min_val) / (max_val - min_val)\n",
    "        normalized_images.append(normalized_image)\n",
    "    \n",
    "    # Convert the list of arrays back to numpy array\n",
    "    normalized_images = np.array(normalized_images)\n",
    "    \n",
    "    # Reshape the images back to their original shape if they were originally 3D\n",
    "    if images.ndim == 3:\n",
    "        normalized_images = normalized_images.reshape(num_images, height, width)\n",
    "    \n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ad1a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def l2_normalize_images(images):\n",
    "    \"\"\"\n",
    "    Perform L2 normalization on an array of images.\n",
    "\n",
    "    Parameters:\n",
    "    - images: numpy array of shape (n_samples, height, width)\n",
    "              representing the images\n",
    "\n",
    "    Returns:\n",
    "    - normalized_images: numpy array of shape (n_samples, height, width)\n",
    "                         containing the normalized images\n",
    "    \"\"\"\n",
    "    # Reshape images to 2D arrays (n_samples, height*width)\n",
    "    n_samples, height, width = images.shape\n",
    "    flattened_images = images.reshape(n_samples, -1)\n",
    "\n",
    "    # L2 normalize each image (row) individually\n",
    "    normalized_images = normalize(flattened_images, norm='l2', axis=1)\n",
    "\n",
    "    # Reshape normalized images back to 3D arrays\n",
    "    normalized_images = normalized_images.reshape(n_samples, height, width)\n",
    "\n",
    "    return normalized_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba598fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (40000, 100, 100) (40000,)\n",
      "Test (10000, 100, 100) (10000,)\n",
      "train_images shape after rotation: (40000, 100, 100)\n",
      "train_images shape after flipping: (40000, 100, 100)\n",
      "train_images shape after rotation and reflection: (40000, 100, 100)\n",
      "(40000, 100, 100)\n",
      "(40000, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "############################# Un-normalised Data #############################\n",
    "\n",
    "# Clean Data\n",
    "print(f\"Train:\",train_images.shape, train_labels.shape)\n",
    "print(f\"Test\",test_images.shape, test_labels.shape)\n",
    "\n",
    "# Data Augmented\n",
    "print(f\"train_images shape after rotation: {train_images_rot.shape}\")\n",
    "print(f\"train_images shape after flipping: {train_images_ref.shape}\")\n",
    "print(f\"train_images shape after rotation and reflection: {train_images_rot_ref.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "############################# Normalised Data #############################\n",
    "##\n",
    "##\n",
    "##\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "################################ l2 ###########################################\n",
    "l2_normalized_jet_images =l2_normalize_images(jetImage)\n",
    "\n",
    "l2_normalized_train_images, l2_normalized_test_images, train_labels, test_labels = train_test_split(l2_normalized_jet_images, particle_label_array, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# l^{2} Normalize train and test images\n",
    "l2_normalized_train_images = l2_normalize_images(train_images)\n",
    "l2_normalized_test_images = l2_normalize_images(test_images)\n",
    "print(l2_normalized_train_images.shape)\n",
    "print(l2_normalized_test_images.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################ Min-Max ###########################################\n",
    "\n",
    "normalized_jet_images = min_max_normalize(jetImage)\n",
    "min_max_normalized_jet_images = normalized_train_images.reshape(jetImage.shape)\n",
    "\n",
    "min_max_normalized_train_images, min_max_normalized_test_images, train_labels, test_labels = train_test_split(min_max_normalized_jet_images, particle_label_array, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(min_max_normalized_train_images.shape)\n",
    "print(min_max_normalized_test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84b5f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__ 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.style \n",
    "import matplotlib as mpl \n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import linalg\n",
    "\n",
    "mpl.rcParams[\"legend.frameon\"] = False\n",
    "mpl.rcParams['figure.dpi']=200 \n",
    "\n",
    "print(\"tf.__version__\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eedc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e94776f6",
   "metadata": {},
   "source": [
    "# NN Models\n",
    "## RAW DATA\n",
    "### NO NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "838dafea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 6s 63ms/step - loss: 1.5912 - accuracy: 0.3544 - val_loss: 1.2781 - val_accuracy: 0.4988\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.3142 - accuracy: 0.4564 - val_loss: 1.1645 - val_accuracy: 0.5445\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.2267 - accuracy: 0.5004 - val_loss: 1.1178 - val_accuracy: 0.5731\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.1801 - accuracy: 0.5246 - val_loss: 1.0800 - val_accuracy: 0.5866\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.1438 - accuracy: 0.5430 - val_loss: 1.0633 - val_accuracy: 0.5976\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.1154 - accuracy: 0.5577 - val_loss: 1.0470 - val_accuracy: 0.6045\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.0863 - accuracy: 0.5697 - val_loss: 1.0266 - val_accuracy: 0.6174\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 1.0685 - accuracy: 0.5819 - val_loss: 1.0240 - val_accuracy: 0.6160\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.0429 - accuracy: 0.5944 - val_loss: 1.0140 - val_accuracy: 0.6255\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.0235 - accuracy: 0.6018 - val_loss: 1.0002 - val_accuracy: 0.6326\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.0047 - accuracy: 0.6095 - val_loss: 0.9970 - val_accuracy: 0.6331\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.9847 - accuracy: 0.6167 - val_loss: 1.0105 - val_accuracy: 0.6277\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.9660 - accuracy: 0.6279 - val_loss: 0.9969 - val_accuracy: 0.6395\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.9491 - accuracy: 0.6339 - val_loss: 1.0014 - val_accuracy: 0.6373\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.9397 - accuracy: 0.6391 - val_loss: 1.0032 - val_accuracy: 0.6331\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.9203 - accuracy: 0.6503 - val_loss: 1.0119 - val_accuracy: 0.6375\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.9140 - accuracy: 0.6512 - val_loss: 1.0037 - val_accuracy: 0.6345\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.9012 - accuracy: 0.6625 - val_loss: 1.0103 - val_accuracy: 0.6419\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.8867 - accuracy: 0.6679 - val_loss: 1.0094 - val_accuracy: 0.6472\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8753 - accuracy: 0.6713 - val_loss: 1.0263 - val_accuracy: 0.6400\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.8704 - accuracy: 0.6724 - val_loss: 1.0065 - val_accuracy: 0.6376\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.8571 - accuracy: 0.6789 - val_loss: 1.0096 - val_accuracy: 0.6435\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.8391 - accuracy: 0.6857 - val_loss: 1.0150 - val_accuracy: 0.6409\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8320 - accuracy: 0.6902 - val_loss: 1.0284 - val_accuracy: 0.6430\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8233 - accuracy: 0.6922 - val_loss: 1.0200 - val_accuracy: 0.6367\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.8184 - accuracy: 0.6950 - val_loss: 1.0316 - val_accuracy: 0.6459\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 0.8043 - accuracy: 0.7021 - val_loss: 1.0261 - val_accuracy: 0.6386\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8041 - accuracy: 0.7016 - val_loss: 1.0258 - val_accuracy: 0.6526\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.7987 - accuracy: 0.7040 - val_loss: 1.0325 - val_accuracy: 0.6436\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.7862 - accuracy: 0.7076 - val_loss: 1.0253 - val_accuracy: 0.6501\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0496 - accuracy: 0.6398\n"
     ]
    }
   ],
   "source": [
    "modelnn = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(150,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(6,activation='linear') \n",
    "])\n",
    "\n",
    "modelnn.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "historynn=modelnn.fit(train_images, \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelnn.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f458715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 5s 66ms/step - loss: 1.6528 - accuracy: 0.3477 - val_loss: 1.2478 - val_accuracy: 0.5067\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.3022 - accuracy: 0.4692 - val_loss: 1.1501 - val_accuracy: 0.5594\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 1.2175 - accuracy: 0.5096 - val_loss: 1.0981 - val_accuracy: 0.5910\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 1.1721 - accuracy: 0.5342 - val_loss: 1.0726 - val_accuracy: 0.5989\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.1325 - accuracy: 0.5513 - val_loss: 1.0575 - val_accuracy: 0.6035\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.1050 - accuracy: 0.5665 - val_loss: 1.0410 - val_accuracy: 0.6112\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.0760 - accuracy: 0.5787 - val_loss: 1.0286 - val_accuracy: 0.6202\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 1.0537 - accuracy: 0.5904 - val_loss: 1.0382 - val_accuracy: 0.6174\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 1.0328 - accuracy: 0.5990 - val_loss: 1.0233 - val_accuracy: 0.6271\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 1.0186 - accuracy: 0.6055 - val_loss: 1.0204 - val_accuracy: 0.6265\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.9962 - accuracy: 0.6152 - val_loss: 1.0129 - val_accuracy: 0.6304\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.9765 - accuracy: 0.6257 - val_loss: 1.0129 - val_accuracy: 0.6264\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.9649 - accuracy: 0.6285 - val_loss: 1.0082 - val_accuracy: 0.6359\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.9495 - accuracy: 0.6364 - val_loss: 0.9991 - val_accuracy: 0.6314\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.9325 - accuracy: 0.6432 - val_loss: 1.0143 - val_accuracy: 0.6410\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 3s 45ms/step - loss: 0.9198 - accuracy: 0.6482 - val_loss: 1.0161 - val_accuracy: 0.6350\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 4s 67ms/step - loss: 0.9027 - accuracy: 0.6582 - val_loss: 1.0272 - val_accuracy: 0.6364\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.8959 - accuracy: 0.6599 - val_loss: 1.0240 - val_accuracy: 0.6385\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8803 - accuracy: 0.6711 - val_loss: 1.0353 - val_accuracy: 0.6356\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 0.8718 - accuracy: 0.6727 - val_loss: 1.0357 - val_accuracy: 0.6367\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.8612 - accuracy: 0.6767 - val_loss: 1.0545 - val_accuracy: 0.6428\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8480 - accuracy: 0.6840 - val_loss: 1.0390 - val_accuracy: 0.6415\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8444 - accuracy: 0.6845 - val_loss: 1.0380 - val_accuracy: 0.6405\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.8337 - accuracy: 0.6903 - val_loss: 1.0626 - val_accuracy: 0.6341\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8199 - accuracy: 0.6937 - val_loss: 1.0510 - val_accuracy: 0.6390\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8158 - accuracy: 0.6969 - val_loss: 1.0682 - val_accuracy: 0.6309\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8054 - accuracy: 0.7035 - val_loss: 1.0611 - val_accuracy: 0.6364\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.7941 - accuracy: 0.7083 - val_loss: 1.0683 - val_accuracy: 0.6407\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.7948 - accuracy: 0.7088 - val_loss: 1.0670 - val_accuracy: 0.6446\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.7853 - accuracy: 0.7128 - val_loss: 1.0740 - val_accuracy: 0.6342\n"
     ]
    }
   ],
   "source": [
    "modelnn_rot_ref = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(150,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(6,activation='linear')  \n",
    "])\n",
    "\n",
    "modelnn_rot_ref.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "historynn_rot_ref=modelnn_rot_ref.fit(train_images_rot_ref, \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelnn_rot_ref.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395f035",
   "metadata": {},
   "source": [
    "### NOISE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "756634a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 8s 105ms/step - loss: 1.7481 - accuracy: 0.3416 - val_loss: 1.3114 - val_accuracy: 0.4782\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.3355 - accuracy: 0.4450 - val_loss: 1.1810 - val_accuracy: 0.5472\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.2406 - accuracy: 0.4913 - val_loss: 1.1187 - val_accuracy: 0.5711\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 1.1828 - accuracy: 0.5246 - val_loss: 1.0854 - val_accuracy: 0.5879\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.1457 - accuracy: 0.5464 - val_loss: 1.0653 - val_accuracy: 0.5949\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 1.1226 - accuracy: 0.5564 - val_loss: 1.0482 - val_accuracy: 0.6075\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.0964 - accuracy: 0.5712 - val_loss: 1.0445 - val_accuracy: 0.6086\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.0777 - accuracy: 0.5778 - val_loss: 1.0251 - val_accuracy: 0.6191\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.0554 - accuracy: 0.5829 - val_loss: 1.0269 - val_accuracy: 0.6181\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.0388 - accuracy: 0.5955 - val_loss: 1.0227 - val_accuracy: 0.6198\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.0217 - accuracy: 0.6036 - val_loss: 1.0124 - val_accuracy: 0.6313\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.9988 - accuracy: 0.6134 - val_loss: 1.0075 - val_accuracy: 0.6327\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.9831 - accuracy: 0.6222 - val_loss: 1.0129 - val_accuracy: 0.6365\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.9707 - accuracy: 0.6263 - val_loss: 1.0182 - val_accuracy: 0.6219\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.9516 - accuracy: 0.6388 - val_loss: 1.0097 - val_accuracy: 0.6249\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.9407 - accuracy: 0.6407 - val_loss: 1.0115 - val_accuracy: 0.6245\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.9228 - accuracy: 0.6502 - val_loss: 1.0086 - val_accuracy: 0.6361\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.9119 - accuracy: 0.6536 - val_loss: 1.0082 - val_accuracy: 0.6361\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8982 - accuracy: 0.6592 - val_loss: 1.0061 - val_accuracy: 0.6350\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.8924 - accuracy: 0.6614 - val_loss: 1.0219 - val_accuracy: 0.6336\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.8768 - accuracy: 0.6702 - val_loss: 1.0212 - val_accuracy: 0.6273\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8681 - accuracy: 0.6733 - val_loss: 1.0397 - val_accuracy: 0.6354\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8579 - accuracy: 0.6799 - val_loss: 1.0170 - val_accuracy: 0.6384\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.8451 - accuracy: 0.6846 - val_loss: 1.0263 - val_accuracy: 0.6414\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8437 - accuracy: 0.6856 - val_loss: 1.0305 - val_accuracy: 0.6309\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.8313 - accuracy: 0.6905 - val_loss: 1.0443 - val_accuracy: 0.6432\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8272 - accuracy: 0.6934 - val_loss: 1.0388 - val_accuracy: 0.6311\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8176 - accuracy: 0.6973 - val_loss: 1.0440 - val_accuracy: 0.6369\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8065 - accuracy: 0.7004 - val_loss: 1.0656 - val_accuracy: 0.6430\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.8004 - accuracy: 0.7035 - val_loss: 1.0459 - val_accuracy: 0.6388\n"
     ]
    }
   ],
   "source": [
    "modelnn_noise = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(150,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(6,activation='linear')  \n",
    "])\n",
    "\n",
    "modelnn_noise.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historynn_noise=modelnn_noise.fit(noise(train_images,y_noise), \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelnn_noise.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc041a04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 10s 118ms/step - loss: 1.5969 - accuracy: 0.3555 - val_loss: 1.2607 - val_accuracy: 0.5020\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.2938 - accuracy: 0.4644 - val_loss: 1.1516 - val_accuracy: 0.5471\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.2222 - accuracy: 0.5028 - val_loss: 1.1141 - val_accuracy: 0.5738\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.1701 - accuracy: 0.5278 - val_loss: 1.0841 - val_accuracy: 0.5914\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.1374 - accuracy: 0.5466 - val_loss: 1.0651 - val_accuracy: 0.5913\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.1085 - accuracy: 0.5640 - val_loss: 1.0443 - val_accuracy: 0.6118\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.0864 - accuracy: 0.5769 - val_loss: 1.0341 - val_accuracy: 0.6145\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 3s 45ms/step - loss: 1.0572 - accuracy: 0.5881 - val_loss: 1.0226 - val_accuracy: 0.6198\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.0423 - accuracy: 0.5933 - val_loss: 1.0238 - val_accuracy: 0.6273\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.0197 - accuracy: 0.6036 - val_loss: 1.0129 - val_accuracy: 0.6308\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.9961 - accuracy: 0.6161 - val_loss: 1.0073 - val_accuracy: 0.6373\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.9816 - accuracy: 0.6201 - val_loss: 1.0186 - val_accuracy: 0.6155\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 0.9608 - accuracy: 0.6311 - val_loss: 1.0061 - val_accuracy: 0.6352\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.9504 - accuracy: 0.6370 - val_loss: 1.0196 - val_accuracy: 0.6226\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.9419 - accuracy: 0.6385 - val_loss: 1.0117 - val_accuracy: 0.6349\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.9200 - accuracy: 0.6463 - val_loss: 1.0249 - val_accuracy: 0.6320\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.9120 - accuracy: 0.6502 - val_loss: 1.0386 - val_accuracy: 0.6292\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 0.8978 - accuracy: 0.6568 - val_loss: 1.0310 - val_accuracy: 0.6398\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 0.8834 - accuracy: 0.6657 - val_loss: 1.0352 - val_accuracy: 0.6292\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8709 - accuracy: 0.6726 - val_loss: 1.0379 - val_accuracy: 0.6354\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 0.8637 - accuracy: 0.6756 - val_loss: 1.0476 - val_accuracy: 0.6315\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 3s 45ms/step - loss: 0.8572 - accuracy: 0.6764 - val_loss: 1.0313 - val_accuracy: 0.6355\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 0.8446 - accuracy: 0.6815 - val_loss: 1.0593 - val_accuracy: 0.6391\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.8320 - accuracy: 0.6904 - val_loss: 1.0534 - val_accuracy: 0.6363\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8278 - accuracy: 0.6912 - val_loss: 1.0487 - val_accuracy: 0.6342\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8194 - accuracy: 0.6939 - val_loss: 1.0464 - val_accuracy: 0.6376\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8070 - accuracy: 0.6998 - val_loss: 1.0482 - val_accuracy: 0.6424\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.7979 - accuracy: 0.7038 - val_loss: 1.0730 - val_accuracy: 0.6357\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.7910 - accuracy: 0.7043 - val_loss: 1.0789 - val_accuracy: 0.6276\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.7952 - accuracy: 0.7075 - val_loss: 1.0517 - val_accuracy: 0.6391\n"
     ]
    }
   ],
   "source": [
    "modelnn_rot_ref_noise = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(150,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(6,activation='linear')  \n",
    "])\n",
    "\n",
    "modelnn_rot_ref_noise.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "historynn_rot_ref_noise=modelnn_rot_ref_noise.fit(noise(train_images_rot_ref,y_noise), \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelnn_rot_ref_noise.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a8229",
   "metadata": {},
   "source": [
    "## NORMALISED DATA\n",
    "### MIN-MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "541d879d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 6s 63ms/step - loss: 1.6809 - accuracy: 0.2998 - val_loss: 1.3925 - val_accuracy: 0.4495\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 1.3949 - accuracy: 0.4303 - val_loss: 1.2435 - val_accuracy: 0.4782\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.3497 - accuracy: 0.4634 - val_loss: 1.2081 - val_accuracy: 0.4990\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 1.3234 - accuracy: 0.4707 - val_loss: 1.2248 - val_accuracy: 0.5042\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 1.2821 - accuracy: 0.4830 - val_loss: 1.1990 - val_accuracy: 0.4975\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 1.2784 - accuracy: 0.4778 - val_loss: 1.2582 - val_accuracy: 0.4954\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 1.2598 - accuracy: 0.4888 - val_loss: 1.1783 - val_accuracy: 0.5126\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 3s 49ms/step - loss: 1.3083 - accuracy: 0.4473 - val_loss: 1.2302 - val_accuracy: 0.4745\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 3s 53ms/step - loss: 1.2679 - accuracy: 0.4790 - val_loss: 1.1924 - val_accuracy: 0.5213\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 1.2512 - accuracy: 0.4843 - val_loss: 1.1609 - val_accuracy: 0.5128\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.2366 - accuracy: 0.4942 - val_loss: 1.1632 - val_accuracy: 0.5303\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 1.2292 - accuracy: 0.5066 - val_loss: 1.1777 - val_accuracy: 0.5415\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 3s 45ms/step - loss: 1.2141 - accuracy: 0.5116 - val_loss: 1.1805 - val_accuracy: 0.5479\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 1.2150 - accuracy: 0.4977 - val_loss: 1.1534 - val_accuracy: 0.5231\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 1.2007 - accuracy: 0.5121 - val_loss: 1.1295 - val_accuracy: 0.5596\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 1.2078 - accuracy: 0.5018 - val_loss: 1.1383 - val_accuracy: 0.5304\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 1.1815 - accuracy: 0.5215 - val_loss: 1.1336 - val_accuracy: 0.5634\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.1680 - accuracy: 0.5268 - val_loss: 1.0996 - val_accuracy: 0.5614\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 3s 49ms/step - loss: 1.1703 - accuracy: 0.5277 - val_loss: 1.1100 - val_accuracy: 0.5595\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 3s 46ms/step - loss: 1.1499 - accuracy: 0.5341 - val_loss: 1.1100 - val_accuracy: 0.5462\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 1.1417 - accuracy: 0.5515 - val_loss: 1.1147 - val_accuracy: 0.5759\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 1.1706 - accuracy: 0.5259 - val_loss: 1.1361 - val_accuracy: 0.5395\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 1.1612 - accuracy: 0.5266 - val_loss: 1.1158 - val_accuracy: 0.5816\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 1.1392 - accuracy: 0.5478 - val_loss: 1.0912 - val_accuracy: 0.5914\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 1.1293 - accuracy: 0.5551 - val_loss: 1.1042 - val_accuracy: 0.5548\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 1.1289 - accuracy: 0.5576 - val_loss: 1.0711 - val_accuracy: 0.6020\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 1.1081 - accuracy: 0.5722 - val_loss: 1.0766 - val_accuracy: 0.6081\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.0956 - accuracy: 0.5782 - val_loss: 1.0912 - val_accuracy: 0.5875\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.1290 - accuracy: 0.5631 - val_loss: 1.0657 - val_accuracy: 0.6140\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.1551 - accuracy: 0.5537 - val_loss: 1.1086 - val_accuracy: 0.5591\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1024 - accuracy: 0.5552\n"
     ]
    }
   ],
   "source": [
    "modelnn_min_max = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(150,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(6,activation='linear')  \n",
    "])\n",
    "\n",
    "modelnn_min_max.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "historynn_min_max=modelnn_min_max.fit(min_max_normalized_train_images, \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelnn_min_max.evaluate(min_max_normalized_test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c5499",
   "metadata": {},
   "source": [
    "### L^{2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a78e21a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 5s 63ms/step - loss: 1.5645 - accuracy: 0.3215 - val_loss: 1.2992 - val_accuracy: 0.4663\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.2676 - accuracy: 0.4670 - val_loss: 1.1277 - val_accuracy: 0.5717\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 1.1784 - accuracy: 0.5201 - val_loss: 1.0641 - val_accuracy: 0.5966\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 1.1220 - accuracy: 0.5559 - val_loss: 1.0169 - val_accuracy: 0.6231\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 3s 46ms/step - loss: 1.0852 - accuracy: 0.5765 - val_loss: 0.9933 - val_accuracy: 0.6267\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 1.0590 - accuracy: 0.5906 - val_loss: 0.9717 - val_accuracy: 0.6394\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 1.0404 - accuracy: 0.6003 - val_loss: 0.9616 - val_accuracy: 0.6399\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 1.0184 - accuracy: 0.6133 - val_loss: 0.9531 - val_accuracy: 0.6457\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 1.0078 - accuracy: 0.6169 - val_loss: 0.9428 - val_accuracy: 0.6469\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.9930 - accuracy: 0.6266 - val_loss: 0.9352 - val_accuracy: 0.6506\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.9795 - accuracy: 0.6297 - val_loss: 0.9426 - val_accuracy: 0.6494\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.9716 - accuracy: 0.6328 - val_loss: 0.9225 - val_accuracy: 0.6586\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.9589 - accuracy: 0.6392 - val_loss: 0.9266 - val_accuracy: 0.6540\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.9498 - accuracy: 0.6432 - val_loss: 0.9170 - val_accuracy: 0.6635\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.9408 - accuracy: 0.6510 - val_loss: 0.9112 - val_accuracy: 0.6676\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.9293 - accuracy: 0.6542 - val_loss: 0.9123 - val_accuracy: 0.6630\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.9264 - accuracy: 0.6552 - val_loss: 0.9161 - val_accuracy: 0.6605\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.9149 - accuracy: 0.6586 - val_loss: 0.9063 - val_accuracy: 0.6685\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.9104 - accuracy: 0.6598 - val_loss: 0.9196 - val_accuracy: 0.6610\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8962 - accuracy: 0.6686 - val_loss: 0.9021 - val_accuracy: 0.6730\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8906 - accuracy: 0.6703 - val_loss: 0.9108 - val_accuracy: 0.6679\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8832 - accuracy: 0.6742 - val_loss: 0.9052 - val_accuracy: 0.6711\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8760 - accuracy: 0.6758 - val_loss: 0.9145 - val_accuracy: 0.6607\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8702 - accuracy: 0.6792 - val_loss: 0.9132 - val_accuracy: 0.6628\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8601 - accuracy: 0.6831 - val_loss: 0.9137 - val_accuracy: 0.6636\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8586 - accuracy: 0.6829 - val_loss: 0.9085 - val_accuracy: 0.6664\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.8521 - accuracy: 0.6852 - val_loss: 0.9169 - val_accuracy: 0.6683\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8429 - accuracy: 0.6888 - val_loss: 0.9145 - val_accuracy: 0.6639\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.8359 - accuracy: 0.6929 - val_loss: 0.9263 - val_accuracy: 0.6675\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.8319 - accuracy: 0.6919 - val_loss: 0.9238 - val_accuracy: 0.6693\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9490 - accuracy: 0.6594\n"
     ]
    }
   ],
   "source": [
    "modelnn_l2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.1), \n",
    "    keras.layers.Dense(150,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32,activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(6,activation='linear')  \n",
    "])\n",
    "\n",
    "modelnn_l2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# modelnn.summary()\n",
    "historynn_l2=modelnn_l2.fit(l2_normalized_train_images, \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelnn_l2.evaluate(l2_normalized_test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a186f9",
   "metadata": {},
   "source": [
    "### ROC CURVE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d4a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "403df79d",
   "metadata": {},
   "source": [
    "# CNN Models\n",
    "## RAW DATA\n",
    "### NO NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15df7f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 52s 796ms/step - loss: 1.4725 - accuracy: 0.3908 - val_loss: 1.1492 - val_accuracy: 0.5071\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 50s 781ms/step - loss: 1.2499 - accuracy: 0.4688 - val_loss: 1.1068 - val_accuracy: 0.5771\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 49s 771ms/step - loss: 1.1819 - accuracy: 0.5107 - val_loss: 1.0409 - val_accuracy: 0.6104\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 49s 772ms/step - loss: 1.1412 - accuracy: 0.5326 - val_loss: 1.0203 - val_accuracy: 0.6229\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 50s 778ms/step - loss: 1.1136 - accuracy: 0.5496 - val_loss: 1.0016 - val_accuracy: 0.6371\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 50s 780ms/step - loss: 1.0854 - accuracy: 0.5712 - val_loss: 0.9800 - val_accuracy: 0.6469\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 50s 783ms/step - loss: 1.0609 - accuracy: 0.5831 - val_loss: 0.9523 - val_accuracy: 0.6596\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 50s 789ms/step - loss: 1.0408 - accuracy: 0.5924 - val_loss: 0.9365 - val_accuracy: 0.6709\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 49s 769ms/step - loss: 1.0311 - accuracy: 0.6012 - val_loss: 0.9314 - val_accuracy: 0.6768\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 49s 764ms/step - loss: 1.0042 - accuracy: 0.6157 - val_loss: 0.9085 - val_accuracy: 0.6800\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 49s 760ms/step - loss: 0.9945 - accuracy: 0.6199 - val_loss: 0.9036 - val_accuracy: 0.6859\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 49s 763ms/step - loss: 0.9753 - accuracy: 0.6284 - val_loss: 0.8917 - val_accuracy: 0.6906\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 49s 765ms/step - loss: 0.9717 - accuracy: 0.6314 - val_loss: 0.8988 - val_accuracy: 0.6787\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 50s 776ms/step - loss: 0.9646 - accuracy: 0.6327 - val_loss: 0.8547 - val_accuracy: 0.7001\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 51s 797ms/step - loss: 0.9511 - accuracy: 0.6429 - val_loss: 0.8748 - val_accuracy: 0.6785\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 51s 790ms/step - loss: 0.9404 - accuracy: 0.6485 - val_loss: 0.8452 - val_accuracy: 0.7048\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 49s 767ms/step - loss: 0.9271 - accuracy: 0.6554 - val_loss: 0.8354 - val_accuracy: 0.7078\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 49s 765ms/step - loss: 0.9218 - accuracy: 0.6582 - val_loss: 0.8672 - val_accuracy: 0.6944\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 49s 769ms/step - loss: 0.9089 - accuracy: 0.6645 - val_loss: 0.8539 - val_accuracy: 0.6991\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 49s 764ms/step - loss: 0.9068 - accuracy: 0.6677 - val_loss: 0.8354 - val_accuracy: 0.7140\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 49s 763ms/step - loss: 0.8960 - accuracy: 0.6725 - val_loss: 0.8435 - val_accuracy: 0.7057\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 49s 762ms/step - loss: 0.8960 - accuracy: 0.6723 - val_loss: 0.8363 - val_accuracy: 0.7080\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 50s 780ms/step - loss: 0.8848 - accuracy: 0.6780 - val_loss: 0.8141 - val_accuracy: 0.7195\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 50s 781ms/step - loss: 0.8789 - accuracy: 0.6788 - val_loss: 0.8114 - val_accuracy: 0.7149\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 50s 784ms/step - loss: 0.8761 - accuracy: 0.6862 - val_loss: 0.8060 - val_accuracy: 0.7109\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 51s 805ms/step - loss: 0.8747 - accuracy: 0.6788 - val_loss: 0.8219 - val_accuracy: 0.7145\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 71s 1s/step - loss: 0.8633 - accuracy: 0.6866 - val_loss: 0.7941 - val_accuracy: 0.7228\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 51s 797ms/step - loss: 0.8560 - accuracy: 0.6916 - val_loss: 0.7962 - val_accuracy: 0.7210\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 48s 756ms/step - loss: 0.8686 - accuracy: 0.6837 - val_loss: 0.7988 - val_accuracy: 0.7195\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 49s 761ms/step - loss: 0.8480 - accuracy: 0.6937 - val_loss: 0.7904 - val_accuracy: 0.7224\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.8149 - accuracy: 0.7105\n"
     ]
    }
   ],
   "source": [
    "modelcnn = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(10, (5, 5), activation='relu', input_shape=(100, 100, 1)),\n",
    "    keras.layers.MaxPooling2D((3, 3)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6, activation='linear')\n",
    "])\n",
    "modelcnn.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historycnn=modelcnn.fit(train_images, \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelcnn.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4738860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 53s 776ms/step - loss: 1.5483 - accuracy: 0.3648 - val_loss: 1.1880 - val_accuracy: 0.5192\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 49s 758ms/step - loss: 1.2587 - accuracy: 0.4633 - val_loss: 1.1059 - val_accuracy: 0.5534\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 48s 748ms/step - loss: 1.1834 - accuracy: 0.5132 - val_loss: 1.0834 - val_accuracy: 0.5995\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 48s 748ms/step - loss: 1.1348 - accuracy: 0.5469 - val_loss: 1.0144 - val_accuracy: 0.6309\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 48s 750ms/step - loss: 1.0923 - accuracy: 0.5713 - val_loss: 0.9853 - val_accuracy: 0.6494\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 48s 750ms/step - loss: 1.0629 - accuracy: 0.5870 - val_loss: 0.9778 - val_accuracy: 0.6581\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 48s 749ms/step - loss: 1.0420 - accuracy: 0.6017 - val_loss: 0.9212 - val_accuracy: 0.6750\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 49s 764ms/step - loss: 1.0145 - accuracy: 0.6169 - val_loss: 0.9229 - val_accuracy: 0.6831\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 48s 751ms/step - loss: 0.9950 - accuracy: 0.6255 - val_loss: 0.8728 - val_accuracy: 0.6901\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 48s 755ms/step - loss: 0.9765 - accuracy: 0.6365 - val_loss: 0.8935 - val_accuracy: 0.6926\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 48s 751ms/step - loss: 0.9691 - accuracy: 0.6389 - val_loss: 0.8768 - val_accuracy: 0.6975\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 48s 750ms/step - loss: 0.9521 - accuracy: 0.6468 - val_loss: 0.8548 - val_accuracy: 0.7040\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 48s 745ms/step - loss: 0.9446 - accuracy: 0.6505 - val_loss: 0.8913 - val_accuracy: 0.6915\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 48s 751ms/step - loss: 0.9408 - accuracy: 0.6528 - val_loss: 0.8492 - val_accuracy: 0.7140\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 48s 758ms/step - loss: 0.9332 - accuracy: 0.6557 - val_loss: 0.8268 - val_accuracy: 0.7139\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 48s 746ms/step - loss: 0.9236 - accuracy: 0.6601 - val_loss: 0.8331 - val_accuracy: 0.7106\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 49s 770ms/step - loss: 0.9016 - accuracy: 0.6692 - val_loss: 0.8218 - val_accuracy: 0.7197\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 52s 813ms/step - loss: 0.9043 - accuracy: 0.6692 - val_loss: 0.8050 - val_accuracy: 0.7240\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 53s 823ms/step - loss: 0.8963 - accuracy: 0.6718 - val_loss: 0.8047 - val_accuracy: 0.7236\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 52s 813ms/step - loss: 0.8906 - accuracy: 0.6744 - val_loss: 0.8119 - val_accuracy: 0.7205\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 53s 829ms/step - loss: 0.8887 - accuracy: 0.6767 - val_loss: 0.8015 - val_accuracy: 0.7236\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 57s 900ms/step - loss: 0.8869 - accuracy: 0.6773 - val_loss: 0.7909 - val_accuracy: 0.7301\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 56s 869ms/step - loss: 0.8794 - accuracy: 0.6789 - val_loss: 0.7924 - val_accuracy: 0.7269\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 55s 860ms/step - loss: 0.8791 - accuracy: 0.6811 - val_loss: 0.7945 - val_accuracy: 0.7278\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 48s 753ms/step - loss: 0.8685 - accuracy: 0.6848 - val_loss: 0.8016 - val_accuracy: 0.7219\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 48s 748ms/step - loss: 0.8651 - accuracy: 0.6861 - val_loss: 0.7902 - val_accuracy: 0.7236\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 48s 745ms/step - loss: 0.8623 - accuracy: 0.6895 - val_loss: 0.7942 - val_accuracy: 0.7220\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 48s 746ms/step - loss: 0.8697 - accuracy: 0.6859 - val_loss: 0.7927 - val_accuracy: 0.7254\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 48s 744ms/step - loss: 0.8579 - accuracy: 0.6883 - val_loss: 0.7727 - val_accuracy: 0.7290\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 47s 741ms/step - loss: 0.8541 - accuracy: 0.6915 - val_loss: 0.7782 - val_accuracy: 0.7314\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.8085 - accuracy: 0.7190\n"
     ]
    }
   ],
   "source": [
    "modelcnn_rot_ref = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(10, (5, 5), activation='relu', input_shape=(100, 100, 1)),\n",
    "    keras.layers.MaxPooling2D((3, 3)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6, activation='linear')\n",
    "])\n",
    "modelcnn_rot_ref.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historycnn_rot_ref=modelcnn_rot_ref.fit(train_images_rot_ref, \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelcnn_rot_ref.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f6742",
   "metadata": {},
   "source": [
    "### NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e287e057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 58s 887ms/step - loss: 1.5788 - accuracy: 0.3612 - val_loss: 1.2154 - val_accuracy: 0.4859\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 52s 817ms/step - loss: 1.3050 - accuracy: 0.4437 - val_loss: 1.1406 - val_accuracy: 0.5109\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 50s 775ms/step - loss: 1.2324 - accuracy: 0.4797 - val_loss: 1.0792 - val_accuracy: 0.5554\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 49s 770ms/step - loss: 1.1820 - accuracy: 0.5105 - val_loss: 1.0655 - val_accuracy: 0.5521\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 50s 788ms/step - loss: 1.1401 - accuracy: 0.5374 - val_loss: 1.0141 - val_accuracy: 0.6269\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 49s 768ms/step - loss: 1.1096 - accuracy: 0.5588 - val_loss: 0.9872 - val_accuracy: 0.6309\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 49s 763ms/step - loss: 1.0861 - accuracy: 0.5768 - val_loss: 0.9886 - val_accuracy: 0.6298\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 48s 757ms/step - loss: 1.0574 - accuracy: 0.5948 - val_loss: 0.9554 - val_accuracy: 0.6529\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 49s 759ms/step - loss: 1.0384 - accuracy: 0.6076 - val_loss: 0.9674 - val_accuracy: 0.6371\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 52s 809ms/step - loss: 1.0295 - accuracy: 0.6152 - val_loss: 0.9490 - val_accuracy: 0.6685\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 50s 778ms/step - loss: 1.0090 - accuracy: 0.6283 - val_loss: 0.8994 - val_accuracy: 0.6781\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 51s 793ms/step - loss: 0.9927 - accuracy: 0.6319 - val_loss: 0.8692 - val_accuracy: 0.6883\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 50s 787ms/step - loss: 0.9737 - accuracy: 0.6423 - val_loss: 0.8815 - val_accuracy: 0.6873\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 49s 771ms/step - loss: 0.9629 - accuracy: 0.6465 - val_loss: 0.8821 - val_accuracy: 0.6916\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 49s 762ms/step - loss: 0.9532 - accuracy: 0.6539 - val_loss: 0.8685 - val_accuracy: 0.6881\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 48s 752ms/step - loss: 0.9496 - accuracy: 0.6595 - val_loss: 0.8727 - val_accuracy: 0.6793\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 48s 752ms/step - loss: 0.9348 - accuracy: 0.6582 - val_loss: 0.8452 - val_accuracy: 0.6944\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 48s 752ms/step - loss: 0.9263 - accuracy: 0.6613 - val_loss: 0.8407 - val_accuracy: 0.6919\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 48s 747ms/step - loss: 0.9203 - accuracy: 0.6650 - val_loss: 0.8325 - val_accuracy: 0.7064\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 52s 819ms/step - loss: 0.9051 - accuracy: 0.6757 - val_loss: 0.8504 - val_accuracy: 0.6946\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 49s 766ms/step - loss: 0.9035 - accuracy: 0.6746 - val_loss: 0.8206 - val_accuracy: 0.7091\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 50s 775ms/step - loss: 0.8905 - accuracy: 0.6790 - val_loss: 0.8235 - val_accuracy: 0.6980\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 49s 759ms/step - loss: 0.8874 - accuracy: 0.6798 - val_loss: 0.8216 - val_accuracy: 0.7089\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 49s 765ms/step - loss: 0.8865 - accuracy: 0.6816 - val_loss: 0.7909 - val_accuracy: 0.7264\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 48s 754ms/step - loss: 0.8744 - accuracy: 0.6839 - val_loss: 0.7903 - val_accuracy: 0.7207\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 51s 793ms/step - loss: 0.8707 - accuracy: 0.6869 - val_loss: 0.7844 - val_accuracy: 0.7254\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 49s 765ms/step - loss: 0.8693 - accuracy: 0.6860 - val_loss: 0.8316 - val_accuracy: 0.7025\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 49s 763ms/step - loss: 0.8618 - accuracy: 0.6897 - val_loss: 0.7701 - val_accuracy: 0.7296\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 49s 759ms/step - loss: 0.8605 - accuracy: 0.6924 - val_loss: 0.7843 - val_accuracy: 0.7294\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 48s 758ms/step - loss: 0.8553 - accuracy: 0.6910 - val_loss: 0.7771 - val_accuracy: 0.7274\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.8012 - accuracy: 0.7162\n"
     ]
    }
   ],
   "source": [
    "modelcnn_noise = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(10, (5, 5), activation='relu', input_shape=(100, 100, 1)),\n",
    "    keras.layers.MaxPooling2D((3, 3)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6, activation='linear')\n",
    "])\n",
    "modelcnn_noise.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historycnn_noise=modelcnn_noise.fit(noise(train_images,y_noise), \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelcnn_noise.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7033fca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - 63s 959ms/step - loss: 1.4956 - accuracy: 0.3895 - val_loss: 1.1752 - val_accuracy: 0.5340\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 50s 784ms/step - loss: 1.2559 - accuracy: 0.4829 - val_loss: 1.1243 - val_accuracy: 0.5839\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 50s 782ms/step - loss: 1.1795 - accuracy: 0.5177 - val_loss: 1.0333 - val_accuracy: 0.6111\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 50s 776ms/step - loss: 1.1280 - accuracy: 0.5532 - val_loss: 1.0175 - val_accuracy: 0.6204\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 51s 800ms/step - loss: 1.0904 - accuracy: 0.5730 - val_loss: 0.9992 - val_accuracy: 0.6390\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 48s 751ms/step - loss: 1.0662 - accuracy: 0.5896 - val_loss: 0.9539 - val_accuracy: 0.6540\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 49s 768ms/step - loss: 1.0329 - accuracy: 0.6033 - val_loss: 0.9534 - val_accuracy: 0.6525\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 50s 786ms/step - loss: 1.0176 - accuracy: 0.6137 - val_loss: 0.9266 - val_accuracy: 0.6604\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 51s 797ms/step - loss: 1.0029 - accuracy: 0.6197 - val_loss: 0.9150 - val_accuracy: 0.6758\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 48s 751ms/step - loss: 0.9762 - accuracy: 0.6348 - val_loss: 0.8949 - val_accuracy: 0.6840\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 48s 752ms/step - loss: 0.9727 - accuracy: 0.6376 - val_loss: 0.9029 - val_accuracy: 0.6786\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 48s 744ms/step - loss: 0.9581 - accuracy: 0.6453 - val_loss: 0.8794 - val_accuracy: 0.6852\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 48s 745ms/step - loss: 0.9421 - accuracy: 0.6531 - val_loss: 0.8524 - val_accuracy: 0.6917\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 53s 830ms/step - loss: 0.9376 - accuracy: 0.6523 - val_loss: 0.8800 - val_accuracy: 0.6917\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 54s 852ms/step - loss: 0.9209 - accuracy: 0.6595 - val_loss: 0.8456 - val_accuracy: 0.6984\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 51s 797ms/step - loss: 0.9255 - accuracy: 0.6544 - val_loss: 0.8496 - val_accuracy: 0.7010\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 50s 778ms/step - loss: 0.9060 - accuracy: 0.6638 - val_loss: 0.8301 - val_accuracy: 0.7050\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 50s 786ms/step - loss: 0.8888 - accuracy: 0.6741 - val_loss: 0.8316 - val_accuracy: 0.7065\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 49s 764ms/step - loss: 0.8980 - accuracy: 0.6706 - val_loss: 0.8275 - val_accuracy: 0.7135\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 48s 754ms/step - loss: 0.8863 - accuracy: 0.6737 - val_loss: 0.8106 - val_accuracy: 0.7091\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 48s 750ms/step - loss: 0.8828 - accuracy: 0.6738 - val_loss: 0.8175 - val_accuracy: 0.7100\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 49s 774ms/step - loss: 0.8733 - accuracy: 0.6779 - val_loss: 0.8024 - val_accuracy: 0.7151\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 50s 784ms/step - loss: 0.8672 - accuracy: 0.6805 - val_loss: 0.7887 - val_accuracy: 0.7259\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 53s 836ms/step - loss: 0.8529 - accuracy: 0.6843 - val_loss: 0.7890 - val_accuracy: 0.7228\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 55s 857ms/step - loss: 0.8481 - accuracy: 0.6883 - val_loss: 0.7992 - val_accuracy: 0.7176\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 50s 787ms/step - loss: 0.8519 - accuracy: 0.6884 - val_loss: 0.7930 - val_accuracy: 0.7176\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 52s 816ms/step - loss: 0.8408 - accuracy: 0.6898 - val_loss: 0.7843 - val_accuracy: 0.7265\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 52s 809ms/step - loss: 0.8351 - accuracy: 0.6953 - val_loss: 0.7785 - val_accuracy: 0.7286\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 51s 793ms/step - loss: 0.8318 - accuracy: 0.6940 - val_loss: 0.7753 - val_accuracy: 0.7287\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 51s 806ms/step - loss: 0.8299 - accuracy: 0.6973 - val_loss: 0.7783 - val_accuracy: 0.7295\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.8061 - accuracy: 0.7127\n"
     ]
    }
   ],
   "source": [
    "modelcnn_rot_ref_noise = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(10, (5, 5), activation='relu', input_shape=(100, 100, 1)),\n",
    "    keras.layers.MaxPooling2D((3, 3)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6, activation='linear')\n",
    "])\n",
    "modelcnn_rot_ref_noise.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historycnn_rot_ref_noise=modelcnn_rot_ref_noise.fit(noise(train_images_rot_ref,y_noise), \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelcnn_rot_ref_noise.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58498dcf",
   "metadata": {},
   "source": [
    "## NORMALISED DATA\n",
    "### MIN-MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a37f0d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "36/64 [===============>..............] - ETA: 20s - loss: 1.6382 - accuracy: 0.2678"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m modelcnn_min_max \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      2\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m10\u001b[39m, (\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m      3\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m6\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m ])\n\u001b[1;32m     13\u001b[0m modelcnn_min_max\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \n\u001b[1;32m     14\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 17\u001b[0m historycnn_min_max\u001b[38;5;241m=\u001b[39mmodelcnn_min_max\u001b[38;5;241m.\u001b[39mfit(min_max_normalized_train_images, \n\u001b[1;32m     18\u001b[0m                   train_labels,\n\u001b[1;32m     19\u001b[0m                   batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, \n\u001b[1;32m     20\u001b[0m                   epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m     21\u001b[0m                   validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     22\u001b[0m                   shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m modelcnn_min_max\u001b[38;5;241m.\u001b[39mevaluate(min_max_normalized_test_images,  test_labels, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    870\u001b[0m   )\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelcnn_min_max = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(10, (5, 5), activation='relu', input_shape=(100, 100, 1)),\n",
    "    keras.layers.MaxPooling2D((3, 3)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6, activation='linear')\n",
    "])\n",
    "modelcnn_min_max.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historycnn_min_max=modelcnn_min_max.fit(min_max_normalized_train_images, \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelcnn_min_max.evaluate(min_max_normalized_test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b916c61",
   "metadata": {},
   "source": [
    "### L^{2} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67393901",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcnn_l2 = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(10, (5, 5), activation='relu', input_shape=(100, 100, 1)),\n",
    "    keras.layers.MaxPooling2D((3, 3)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6, activation='linear')\n",
    "])\n",
    "modelcnn_l2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historycnn_l2=modelcnn_l2.fit(l2_normalized_train_images, \n",
    "                  train_labels,\n",
    "                  batch_size=500, \n",
    "                  epochs=30,\n",
    "                  validation_split=0.2,\n",
    "                  shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelcnn_l2.evaluate(l2_normalized_test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd9c50",
   "metadata": {},
   "source": [
    "### ROC CURVE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe03bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e115a7c6",
   "metadata": {},
   "source": [
    "# PCA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c16eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eignvecvals(image):\n",
    "    \n",
    "    \"\"\"\n",
    "    Perform Principal Component Analysis (PCA) on a set of images\n",
    "\n",
    "    Parameters:\n",
    "    - image: A 3D array representing a set of images\n",
    "\n",
    "    Returns:\n",
    "    - vecs: Matrix of eigenvectors obtained from PCA\n",
    "    - vals: Array of eigenvalues obtained from PC\n",
    "    - x: Centered data after subtracting the mean\n",
    "    - mu: Mean of the original data\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    len_image = len(image)\n",
    "    \n",
    "    X=np.reshape(image,(len_image,100*100))\n",
    "    \n",
    "    mu=np.mean(X,axis=0)\n",
    "    x=X-mu\n",
    "    \n",
    "    \n",
    "    rho=np.cov(x,rowvar=False) \n",
    "    \n",
    "    \n",
    "    vals,vecs=linalg.eigh(rho)\n",
    "    \n",
    "    vecs=np.flip(vecs)\n",
    "    vals=np.flip(vals)\n",
    "\n",
    "    \n",
    "    return vecs, vals , x , mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a05b4d",
   "metadata": {},
   "source": [
    "\n",
    "## RAW DATA\n",
    "### NO NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ab28be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vecs, test_vals, x, mu  = eignvecvals(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "097a21d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "128/128 [==============================] - 8s 40ms/step - loss: 1.6874 - accuracy: 0.2358 - val_loss: 1.4918 - val_accuracy: 0.4565\n",
      "Epoch 2/30\n",
      "128/128 [==============================] - 2s 12ms/step - loss: 1.4565 - accuracy: 0.3548 - val_loss: 1.3388 - val_accuracy: 0.5017\n",
      "Epoch 3/30\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 1.3081 - accuracy: 0.4649 - val_loss: 1.1762 - val_accuracy: 0.5451\n",
      "Epoch 4/30\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 1.2215 - accuracy: 0.4930 - val_loss: 1.1271 - val_accuracy: 0.5620\n",
      "Epoch 5/30\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 1.1782 - accuracy: 0.5180 - val_loss: 1.1003 - val_accuracy: 0.5667\n",
      "Epoch 6/30\n",
      "128/128 [==============================] - 1s 11ms/step - loss: 1.1484 - accuracy: 0.5340 - val_loss: 1.0795 - val_accuracy: 0.5803\n",
      "Epoch 7/30\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 1.1311 - accuracy: 0.5432 - val_loss: 1.0665 - val_accuracy: 0.5791\n",
      "Epoch 8/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 1.1071 - accuracy: 0.5528 - val_loss: 1.0529 - val_accuracy: 0.5826\n",
      "Epoch 9/30\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 1.0898 - accuracy: 0.5617 - val_loss: 1.0413 - val_accuracy: 0.5842\n",
      "Epoch 10/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 1.0787 - accuracy: 0.5675 - val_loss: 1.0304 - val_accuracy: 0.5870\n",
      "Epoch 11/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 1.0650 - accuracy: 0.5754 - val_loss: 1.0202 - val_accuracy: 0.5919\n",
      "Epoch 12/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 1.0545 - accuracy: 0.5811 - val_loss: 1.0148 - val_accuracy: 0.5950\n",
      "Epoch 13/30\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 1.0422 - accuracy: 0.5869 - val_loss: 1.0114 - val_accuracy: 0.5954\n",
      "Epoch 14/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 1.0345 - accuracy: 0.5923 - val_loss: 1.0001 - val_accuracy: 0.6003\n",
      "Epoch 15/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 1.0257 - accuracy: 0.5919 - val_loss: 0.9998 - val_accuracy: 0.6024\n",
      "Epoch 16/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 1.0177 - accuracy: 0.5953 - val_loss: 0.9915 - val_accuracy: 0.6010\n",
      "Epoch 17/30\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 1.0129 - accuracy: 0.6018 - val_loss: 0.9938 - val_accuracy: 0.6040\n",
      "Epoch 18/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 1.0007 - accuracy: 0.6058 - val_loss: 0.9867 - val_accuracy: 0.6036\n",
      "Epoch 19/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9954 - accuracy: 0.6100 - val_loss: 0.9852 - val_accuracy: 0.6062\n",
      "Epoch 20/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9929 - accuracy: 0.6100 - val_loss: 0.9805 - val_accuracy: 0.6086\n",
      "Epoch 21/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9827 - accuracy: 0.6118 - val_loss: 0.9789 - val_accuracy: 0.6101\n",
      "Epoch 22/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9791 - accuracy: 0.6154 - val_loss: 0.9799 - val_accuracy: 0.6106\n",
      "Epoch 23/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9706 - accuracy: 0.6183 - val_loss: 0.9812 - val_accuracy: 0.6076\n",
      "Epoch 24/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9640 - accuracy: 0.6231 - val_loss: 0.9686 - val_accuracy: 0.6169\n",
      "Epoch 25/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9614 - accuracy: 0.6237 - val_loss: 0.9750 - val_accuracy: 0.6184\n",
      "Epoch 26/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9572 - accuracy: 0.6259 - val_loss: 0.9800 - val_accuracy: 0.6110\n",
      "Epoch 27/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9531 - accuracy: 0.6282 - val_loss: 0.9708 - val_accuracy: 0.6192\n",
      "Epoch 28/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9453 - accuracy: 0.6328 - val_loss: 0.9731 - val_accuracy: 0.6155\n",
      "Epoch 29/30\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.9434 - accuracy: 0.6332 - val_loss: 0.9647 - val_accuracy: 0.6223\n",
      "Epoch 30/30\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.9394 - accuracy: 0.6332 - val_loss: 0.9634 - val_accuracy: 0.6185\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9847 - accuracy: 0.6151\n"
     ]
    }
   ],
   "source": [
    "modelpca = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)), \n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6,activation='linear') \n",
    "])\n",
    "\n",
    "modelpca.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "P=np.dot(x,test_vecs)\n",
    "P_n_100_dot = np.dot(P[:,0:2000],test_vecs.T[0:2000,:]) + mu\n",
    "P_n_100_image = np.reshape(P_n_100_dot,(40000,100,100))\n",
    "\n",
    "\n",
    "historypca = modelpca.fit(P_n_100_image,\n",
    "                          train_labels,\n",
    "                          batch_size=250, \n",
    "                          epochs=30,\n",
    "                          validation_split=0.2,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelpca.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88fce772",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eignvecvals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vecs_rot_ref, vals_rot_ref, x_rot_ref, mu_rot_ref  \u001b[38;5;241m=\u001b[39m eignvecvals(train_images_rot_ref)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eignvecvals' is not defined"
     ]
    }
   ],
   "source": [
    "vecs_rot_ref, vals_rot_ref, x_rot_ref, mu_rot_ref  = eignvecvals(train_images_rot_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18542d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpca_rot_ref = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)), \n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6,activation='linear') \n",
    "])\n",
    "\n",
    "modelpca_rot_ref.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "P_rot_ref=np.dot(x_rot_ref,vecs_rot_ref)\n",
    "P_n_100_dot_rot_ref = np.dot(P_rot_ref[:,0:2000],vecs_rot_ref.T[0:2000,:]) + mu_rot_ref\n",
    "P_n_100_image_rot_ref = np.reshape(P_n_100_dot_rot_ref,(40000,100,100))\n",
    "\n",
    "\n",
    "historypca_rot_ref = modelpca_rot_ref.fit(P_n_100_image_rot_ref,\n",
    "                          train_labels,\n",
    "                          batch_size=250, \n",
    "                          epochs=30,\n",
    "                          validation_split=0.2,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelpca_rot_ref.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec871e15",
   "metadata": {},
   "source": [
    "## NOISE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ec4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_noise, vals_noise, x_noise, mu_noise  = eignvecvals(noise(train_images,y_noise))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a739f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpca_noise = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)), \n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6,activation='linear') \n",
    "])\n",
    "\n",
    "modelpca_noise.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "P_noise=np.dot(x_noise,vecs_noise)\n",
    "P_n_100_dot_noise = np.dot(P_noise[:,0:2000],vecs_noise.T[0:2000,:]) + mu_noise\n",
    "P_n_100_image_noise = np.reshape(P_n_100_dot_noise,(40000,100,100))\n",
    "\n",
    "\n",
    "historypca_noise = modelpca_noise.fit(P_n_100_image_noise,\n",
    "                          train_labels,\n",
    "                          batch_size=250, \n",
    "                          epochs=30,\n",
    "                          validation_split=0.2,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelpca_noise.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_rot_ref_noise, vals_rot_ref_noise, x_rot_ref_noise, mu_rot_ref_noise  = eignvecvals(noise(train_images_rot_ref,y_noise))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpca_rot_ref_noise = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)), \n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6,activation='linear') \n",
    "])\n",
    "\n",
    "modelpca_rot_ref_noise.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "P_rot_ref_noise=np.dot(x_rot_ref_noise,vecs_rot_ref_noise)\n",
    "P_n_100_dot_rot_ref_noise = np.dot(P_rot_ref_noise[:,0:2000],vecs_rot_ref_noise.T[0:2000,:]) + mu_rot_ref_noise\n",
    "P_n_100_image_rot_ref_noise = np.reshape(P_n_100_dot_rot_ref_noise,(40000,100,100))\n",
    "\n",
    "\n",
    "historypca_rot_ref_noise = modelpca_rot_ref_noise.fit(P_n_100_image_noise,\n",
    "                          train_labels,\n",
    "                          batch_size=250, \n",
    "                          epochs=30,\n",
    "                          validation_split=0.2,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelpca_rot_ref_noise.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd44c5a",
   "metadata": {},
   "source": [
    "## NORMALISED DATA\n",
    "### MIN-MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006714c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_norm_min_max, vals_norm_min_max, x_norm_min_max, mu_norm_min_max  = eignvecvals(min_max_normalized_train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dbe902",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpca_norm_min_max = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)), \n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6,activation='linear') \n",
    "])\n",
    "\n",
    "modelpca_norm_min_max.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "P_norm_min_max=np.dot(x_norm_min_max,vecs_norm_min_max)\n",
    "P_n_100_dot_norm_min_max = np.dot(P_norm_min_max[:,0:2000],vecs_norm_min_max.T[0:2000,:]) + mu_norm_min_max\n",
    "P_n_100_image_norm_min_max = np.reshape(P_n_100_dot_norm_min_max,(40000,100,100))\n",
    "\n",
    "\n",
    "historypca_norm_min_max = modelpca_norm_min_max.fit(P_n_100_image_norm_min_max,\n",
    "                          train_labels,\n",
    "                          batch_size=250, \n",
    "                          epochs=30,\n",
    "                          validation_split=0.2,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelpca_norm_min_max.evaluate(min_max_normalized_test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913c2c4",
   "metadata": {},
   "source": [
    "### L^{2} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_norm_l2, vals_norm_l2, x_norm_l2, mu_norm_l2  = eignvecvals(l2_normalized_train_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpca_norm_l2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(100,100)), \n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    keras.layers.Dense(64,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32,activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(6,activation='linear') \n",
    "])\n",
    "\n",
    "modelpca_norm_l2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "P_norm_l2=np.dot(x_norm_l2,vecs_norm_l2)\n",
    "P_n_100_dot_norm_l2 = np.dot(P_norm_l2[:,0:2000],vecs_norm_l2.T[0:2000,:]) + mu_norm_l2\n",
    "P_n_100_image_norm_l2 = np.reshape(P_n_100_dot_norm_l2,(40000,100,100))\n",
    "\n",
    "\n",
    "historypca_norm_l2 = modelpca_norm_l2.fit(P_n_100_image_norm_l2,\n",
    "                          train_labels,\n",
    "                          batch_size=250, \n",
    "                          epochs=30,\n",
    "                          validation_split=0.2,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loss, test_acc = modelpca_norm_l2.evaluate(l2_normalized_test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d7fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98799353",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
